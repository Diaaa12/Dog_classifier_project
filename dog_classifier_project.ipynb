{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9fziCQuph24"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading data\n",
        "!pip install -q gdown\n",
        "!gdown --id 19Iv_ln4_JRdf_A_IcKQdDmN6Sp2HH3hu\n",
        "!unzip dog_classifier.zip"
      ],
      "metadata": {
        "id": "lDSeOSYmsTqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning\n",
        "path = '/content/train'\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "    for img_file in os.listdir(os.path.join(path,folder)):\n",
        "        img_file = os.path.join(path, folder, img_file)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_file)\n",
        "            if img.mode != 'RGB':\n",
        "                os.remove(img_file)\n",
        "        except:\n",
        "            os.remove(img_file)\n"
      ],
      "metadata": {
        "id": "WWIEtmWKpvfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/test'\n",
        "for folder in os.listdir(path):\n",
        "    for img_file in os.listdir(os.path.join(path,folder)):\n",
        "        img_file = os.path.join(path, folder, img_file)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_file)\n",
        "            if img.mode != 'RGB':\n",
        "                os.remove(img_file)\n",
        "        except:\n",
        "            os.remove(img_file)"
      ],
      "metadata": {
        "id": "FTFqXAS5qJLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre processing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(244),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "    ])\n",
        "\n",
        "train_set = datasets.ImageFolder('/content/train' ,  transform = transform)\n",
        "test_set = datasets.ImageFolder('/content/test' ,  transform = transform)\n",
        "\n",
        "train_set = DataLoader(dataset = train_set , batch_size=6000, shuffle=True)\n",
        "test_set = DataLoader(dataset = test_set , batch_size=6000, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('using device:' , device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdeAEvjRqGj3",
        "outputId": "22fb23f8-0279-4534-8f3e-93b8ca94199a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building model\n",
        "\n",
        "#CNN model\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3,out_channels =6, kernel_size =4)\n",
        "        self.conv2 = nn.Conv2d(in_channels= 6,out_channels =12, kernel_size =4)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 12,out_channels =14, kernel_size =4)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 14,out_channels =16, kernel_size =4)\n",
        "        self.conv5 = nn.Conv2d(in_channels = 16,out_channels =20, kernel_size =4)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 20*4*4 , out_features = 250)\n",
        "        self.fc2 = nn.Linear(in_features = 250 , out_features = 200)\n",
        "        self.fc3 = nn.Linear(in_features = 200 , out_features = 50)\n",
        "        self.fc4 = nn.Linear(in_features = 50 , out_features = 10)\n",
        "        self.fc5 = nn.Linear(in_features = 10 , out_features = 2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.pool(f.relu(self.conv1(x)))\n",
        "        x= self.pool(f.relu(self.conv2(x)))\n",
        "        x= self.pool(f.relu(self.conv3(x)))\n",
        "        x= self.pool(f.relu(self.conv4(x)))\n",
        "        x= self.pool(f.relu(self.conv5(x)))\n",
        "\n",
        "        x.reshape(-1, 20*4*4)\n",
        "        x= self.dropout(f.relu(self.fc1(x)))\n",
        "        x= self.dropout(f.relu(self.fc2(x)))\n",
        "        x= self.dropout(f.relu(self.fc3(x)))\n",
        "        x= self.dropout(f.relu(self.fc4(x)))\n",
        "        x= self.fc5(x)\n",
        "        return x\n",
        "\n",
        "model =  Model().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEZFJr4lqV6w",
        "outputId": "ec61ef04-a647-4c5e-c89f-2b3d3134d405",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv3): Conv2d(12, 14, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv4): Conv2d(14, 16, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv5): Conv2d(16, 20, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=320, out_features=250, bias=True)\n",
            "  (fc2): Linear(in_features=250, out_features=200, bias=True)\n",
            "  (fc3): Linear(in_features=200, out_features=50, bias=True)\n",
            "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
            "  (fc5): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------OR-----------"
      ],
      "metadata": {
        "id": "ifoSrN9TqW_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using pretrained model\n",
        "from torchvision import models\n",
        "from collections import OrderedDict\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "    #\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    model.classifier = nn.Sequential(OrderedDict([\n",
        "                              ('fc1', nn.Linear(1024, 512)),\n",
        "                              ('relu', nn.ReLU()),\n",
        "                              ('dropout', nn.Dropout(0.2)),\n",
        "                              ('fc2', nn.Linear(512, 102)),\n",
        "                              ('output', nn.LogSoftmax(dim=1))\n",
        "                              ]))\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "iroFqp01qZlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "UG4wDmBQqcWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(15):\n",
        "    total_correct = 0\n",
        "    running_loss = 0\n",
        "    for i, (inputs,labels) in enumerate(train_set):\n",
        "        inputs,labels = inputs.to(device) , labels.to(device)\n",
        "        output = model(inputs)\n",
        "        output_idx = torch.argmax(output, dim=1)\n",
        "        total_correct += (labels == output_idx).sum().item()\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output,labels)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch: {epoch} Loss: {running_loss / train_len} Accuracy: {(total_correct / train_len) * 100}%')\n",
        "\n",
        "print('finished training')"
      ],
      "metadata": {
        "id": "bEgabloOsYLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model\n",
        "\n",
        "with torch.no_grad():\n",
        " model.eval()\n",
        " total_loss =0\n",
        " total_correct =0\n",
        "\n",
        "for inputs,labels in test_set:\n",
        "    labels= labels.to(device)\n",
        "    outputs = model(inputs.to(device))\n",
        "    loss = criterion(outputs,labels)\n",
        "    total_loss += loss.item() * inputs.size(0)\n",
        "    output_idx = torch.argmax(outputs, dim=1)\n",
        "    total_correct += sum(labels == output_idx)\n",
        "\n",
        "print(f'Accuracy : {(total_correct/test_len)*100}% Loss:{total_loss/test_len}')"
      ],
      "metadata": {
        "id": "G-Vtr4y6qf3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model\n",
        "torch.save(model.state_dict() , 'dogclassifier.pt')"
      ],
      "metadata": {
        "id": "excxj_s8qiDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "with torch.no_grad():\n",
        "    model = model().to(device)\n",
        "    model.load_state_dict(torch.load('dogclassifier.pt'))\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "dXfodp5bqkbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}